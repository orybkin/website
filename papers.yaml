papers:
  - name: video2policy
    title:
      link: https://arxiv.org/pdf/2502.09886.pdf
      name: "Video2Policy: Scaling up Manipulation Tasks in Simulation through Internet Videos"
    authors:
      - name: Weirui Ye
        href: https://yewr.github.io/
      - name: Fangchen Liu
        href: https://fangchenliu.github.io/
      - name: Zheng Ding
        href: https://scholar.google.com/citations?user=TOYBXFQAAAAJ&hl=en
      - name: Yang Gao
        href: https://yang-gao.weebly.com/
      - me: true
      - name: Pieter Abbeel
        href: https://people.eecs.berkeley.edu/~pabbeel/
    conference:
      name: ArXiv
      year: 2025
    links:
      - name: arXiv
        href: https://arxiv.org/abs/2502.09886
    description: We automatically convert internet videos to manipulation tasks for reinforcement learning. Objects, tasks, and rewards are reconstructed using foundation models.

  - name: qscaled
    title:
      link: https://arxiv.org/pdf/2502.04327.pdf
      name: "Value-Based Deep RL Scales Predictably"
    authors:
      - me: true
      - name: Michal Nauman
        href: https://scholar.google.com/citations?user=GnEVRtQAAAAJ&hl=en
      - name: Preston Fu
        href: https://www.prestonfu.com/
      - name: Charlie Snell
        href: https://sea-snell.github.io/
      - name: Pieter Abbeel
        href: https://people.eecs.berkeley.edu/~pabbeel/
      - name: Sergey Levine
        href: https://people.eecs.berkeley.edu/~svlevine/
      - name: Aviral Kumar
        href: https://aviralkumar2907.github.io/
    conference:
      name: ArXiv
      year: 2025 </br> ICLR Robot Learning Workshop, 2025 (<oral>oral presentation</oral>) # acceptance rate 15#
    links:
      - name: arXiv
        href: https://arxiv.org/abs/2502.04327
      - name: thread
        href: https://x.com/_oleh/status/1889016893140516880
    description: We build empirical models of the data-compute Pareto frontier, optimal resource allocation across data and compute, and hyperparameter dependencies for value-based RL. From small-scale runs, we can extrapolate towards higher data, compute, and performance. 
    highlighted: true

  - name: metra
    title:
      link: https://arxiv.org/pdf/2310.08887.pdf
      name: "METRA: Scalable Unsupervised RL with Metric-Aware Abstraction"
    authors:
      - name: Seohong Park
        href: https://seohong.me/
      - me: true
      - name: Sergey Levine
        href: https://people.eecs.berkeley.edu/~svlevine/
    conference:
      name: International Conference on Learning Representations (ICLR)
      year: 2024 (<oral>oral</oral>, 1% acceptance rate)
    links:
      - name: project page & videos
        href: https://seohong.me/projects/metra/
      - name: arXiv
        href: https://arxiv.org/abs/2310.08887
      - name: code
        href: https://github.com/seohongpark/METRA
    description: METRA is an unsupervised agent that scales to complex visual environments and diverse skills. It learns skills in a latent space using the temporal distance as a metric.
    highlighted: true

  - name: scaffolder
    title:
      link: https://openreview.net/pdf?id=EpVe8jAjdx
      name: "Privileged Sensing Scaffolds Reinforcement Learning"
    authors:
      - name: Edward S. Hu
        href: https://edwardshu.com/
      - name: James Springer
        href: https://www.grasp.upenn.edu/people/james-springer/
      - me: true
      - name: Dinesh Jayaraman
        href: https://www.seas.upenn.edu/~dineshj/
    conference:
      name: International Conference on Learning Representations (ICLR)
      year: 2024 (<oral>spotlight</oral>, 4% acceptance rate)
    links:
      - name: project page & videos
        href: https://penn-pal-lab.github.io/scaffolder/
      - name: arXiv
        href: https://arxiv.org/abs/2405.14853
      - name: code
        href: https://github.com/penn-pal-lab/scaffolder
    description: We study "sensory scaffolding" where privileged input improves training components but is not fed into the policy. Even with limited sensing, our Scaffolder agent can be robust and do information gathering.


  - name: peg
    title:
      link: https://openreview.net/pdf?id=6qeBuZSo7Pr
      name: "Planning Goals for Exploration"
    authors:
      - name: Edward S. Hu
        href: https://edwardshu.com/
      - name: Richard Chang
        href: https://www.linkedin.com/in/richard-chang-bb5475168/
      - me: true
      - name: Dinesh Jayaraman
        href: https://www.seas.upenn.edu/~dineshj/
    conference:
      name: International Conference on Learning Representations (ICLR)
      year: 2023 (<oral>spotlight</oral>, 6% acceptance rate) </br> CoRL Roboadapt Workshop, 2022 (<oral>best paper award</oral>, 6% acceptance rate)
    links:
      - name: project page & videos
        href: https://penn-pal-lab.github.io/peg/
      - name: arXiv
        href: https://arxiv.org/abs/2303.13002
      - name: talk
        href: https://iclr.cc/virtual/2023/poster/11390
      - name: code
        href: https://github.com/penn-pal-lab/peg
      - name: colab
        href: https://colab.research.google.com/drive/1mbr8HHjWAhTQHUP2Y-QOgByuOOXBpusD?usp=sharing
    description: PEG uses world models to set exploratory goals that prompt the goal-conditioned policy to reach states with high exploration potential. This enables the agent to explore and solve challenging long-horizon tasks.
    highlighted: true

  - name: cascade
    title:
      link: https://proceedings.neurips.cc/paper_files/paper/2022/file/ab6a2c6ee757afe43882121281f6065c-Paper-Conference.pdf
      name: "Learning General World Models in a Handful of Reward-Free Deployments"
    authors:
      - name: Yingchen Xu
        star: True
        href: https://yingchenxu.com/
      - name: Jack Parker-Holder
        star: True
        href: https://jparkerholder.github.io/
      - name: Aldo Pacchiano
        star: True
        href: https://www.aldopacchiano.ai/
      - name: Phillip J. Ball
        star: True
        href: https://philipjball.github.io/
      - me: true
      - name: Stephen J. Roberts
        href: https://www.robots.ox.ac.uk/~sjrob/
      - name: Tim Rockt√§schel
        href: https://rockt.github.io/
      - name: Edward Grefenstette
        href: https://www.egrefen.com/
    conference:
      name: Neural Information Processing Systems (NeurIPS)
      year: 2022
    links:
      - name: project page & videos
        href: https://yingchenxu.com/cascade/
      - name: arXiv
        href: https://arxiv.org/abs/2210.12719
    description: CASCADE trains a population of exploration agents by maximizing the diversity and information gathered by the population. It can explore and learn a world model without any supervision even with a limited number of deployments.

  - name: roboaware
    title:
      link: https://openreview.net/pdf?id=o0ehFykKVtr
      name: "Transferable Visual Control Policies Through Robot-Awareness"
    authors:
      - name: Edward S. Hu
        href: https://edwardshu.com/
      - name: Kun Huang
        href: https://voyager1998.github.io/
      - me: true
      - name: Dinesh Jayaraman
        href: https://www.seas.upenn.edu/~dineshj/
    conference:
      name: International Conference on Learning Representations (ICLR)
      year: 2022 </br> <i>ICLR Workshop on Generalizable Policy Learning</i>, 2022 (<oral>oral presentation</oral>, 5% acceptance rate)
    links:
      - name: project page & videos
        href: https://hueds.github.io/rac/
      - name: arXiv
        href: https://arxiv.org/abs/2107.09047
      - name: talk (5 min)
        href: https://www.youtube.com/watch?v=Q_9u6B54iAc
    description: Through self-awareness, our robots learn separate robot and world dynamics, enabling better cost functions for visual MBRL and zero-shot transfer from a single robot to multiple other robots.
    nofig: True

  - name: LEXA
    title:
      link: https://arxiv.org/pdf/2110.09514.pdf
      name: Discovering and Achieving Goals via World Models
    authors:
      - name: Russell Mendonca
        href: https://russellmendonca.github.io/
        star: true
      - me: true
        star: true
      - name: Kostas Daniilidis
        href: http://www.cis.upenn.edu/~kostas
      - name: Danijar Hafner
        href: https://danijar.com/
      - name: Deepak Pathak
        href: https://www.cs.cmu.edu/~dpathak/
    conference:
      name: Neural Information Processing Systems (NeurIPS)
      year: 2021 </br> <i>ICML Workshop on Unsupervised RL</i>, 2021 (<oral>oral presentation</oral>, 6% acceptance rate) </br> <i>ICML Workshop on Self-Supervised Learning</i>, 2021 (<oral>oral presentation</oral>)
      # URL is 3 out of 47 submissions, 6.3%
      # The other workshop has 13% acceptance rate or lower: 7 out of 52 accepted posters
    links:
      - name: project page & videos
        href: https://orybkin.github.io/lexa/
      - name: arXiv
        href: https://arxiv.org/abs/2110.09514
      - name: poster
        href: images/lexa_poster.pdf
      - name: video (2 min)
        href: https://www.youtube.com/watch?v=LnZj2lZYD3k
      - name: talk (13 min)
        href: https://www.youtube.com/watch?v=WWHlQbigQp4
      - name: code
        href: https://github.com/orybkin/lexa
    description: Latent Explorer Achiever (LEXA) discovers visual goals and learns to reach them in imagination, without any supervision. With forward-looking exploration, LEXA solves hard tasks previously only solved with demonstrations or rewards.
    highlighted: true


  - name: latco
    title:
      link: https://arxiv.org/pdf/2106.13229.pdf
      name: Model-Based Reinforcement Learning via Latent-Space Collocation
    authors:
      - me: true
        star: true
      - name: Chuning Zhu
        href: https://www.seas.upenn.edu/~zchuning/
        star: true
      - name: Anusha Nagabandi
        href: https://www.linkedin.com/in/anusha-nagabandi-a4923bba
      - name: Kostas Daniilidis
        href: http://www.cis.upenn.edu/~kostas
      - name: Igor Mordatch
        href: https://twitter.com/imordatch
      - name: Sergey Levine
        href: https://people.eecs.berkeley.edu/~svlevine
    conference:
      name: International Conference on Machine Learning (ICML)
      year: 2021
    links:
      - name: project page & videos
        href: https://orybkin.github.io/latco/
      - name: arXiv
        href: https://arxiv.org/abs/2106.13229
      - name: poster
        href: images/latco_poster.pdf
      - name: talk (5 min)
        href: https://www.youtube.com/watch?v=skc0e4KYNcw
      - name: code
        href: https://github.com/zchuning/latco
    description: Our planner, LatCo, solves multi-stage long-horizon tasks where prior work fails. By optimizing a sequence of future latent states instead of optimizing actions directly, it quickly discovers the high-reward region to create effective visual plans.

  - name: sigma
    title:
      link: https://arxiv.org/pdf/2006.13202.pdf
      name: Simple and Effective VAE Training with Calibrated Decoders
    authors:
      - me: true
      - name: Kostas Daniilidis
        href: http://www.cis.upenn.edu/~kostas
      - name: Sergey Levine
        href: https://people.eecs.berkeley.edu/~svlevine
    conference:
      name: International Conference on Machine Learning (ICML)
      year: 2021
    links:
      - name: project page & videos
        href: https://orybkin.github.io/sigma-vae/
      - name: arXiv
        href: https://arxiv.org/abs/2006.13202
      - name: poster
        href: images/sigma_poster.pdf
      - name: talk (5 min)
        href: https://www.youtube.com/watch?v=6UMzH68RwGM
      - name: code
        href: https://github.com/orybkin/sigma-vae
    description: Commonly used uncalibrated decoders adversely affect VAE training. However, learning appropriate calibrated decoders yields better samples, is simple to implement, and does not require the common heuristic weight on the KL divergence.
    highlighted: true

  - name: RLV
    title:
      link: https://arxiv.org/pdf/2011.06507.pdf
      name: "Reinforcement Learning with Videos: Combining Offline Observations with Interaction"
    authors:
      - name: Karl Schmeckpeper
        hre: https://sites.google.com/view/karlschmeckpeper
      - me: true
      - name: Kostas Daniilidis
        href: http://www.cis.upenn.edu/~kostas
      - name: Sergey Levine
        href: https://people.eecs.berkeley.edu/~svlevine
      - name: Chelsea Finn
        href: https://ai.stanford.edu/~cbfinn/
    conference:
      name: Conference on Robot Learning (CoRL)
      year: 2020 (<oral>oral presentation</oral>, 4% acceptance rate)
    links:
      - name: project page & videos
        href: https://sites.google.com/view/rl-with-videos
      - name: arXiv
        href: https://arxiv.org/abs/2011.06507
      - name: talk (5 min)
        href: https://www.youtube.com/watch?v=aIWr4fhzPFA
      - name: code
        href: https://github.com/kschmeckpeper/rl_with_videos
    description: We use offline observations of humans jointly with online robot interaction data in a joint reinforcement learning algortihm. The resulting approach is able to learn from real-world human videos to solve challenging robotic tasks.

  - name: GCP
    title:
      link: https://arxiv.org/pdf/2006.13205.pdf
      name: Long-Horizon Visual Planning with Goal-Conditioned Hierarchical Predictors
    authors:
      - name: Karl Pertsch
        href: https://kpertsch.github.io/
        star: true
      - me: true
        star: true
      - name: Frederik Ebert
        href: https://febert.github.io
      - name: Chelsea Finn
        href: https://ai.stanford.edu/~cbfinn/
      - name: Dinesh Jayaraman
        href: https://www.seas.upenn.edu/~dineshj
      - name: Sergey Levine
        href: https://people.eecs.berkeley.edu/~svlevine
    conference:
      name: Neural Information Processing Systems (NeurIPS)
      year: 2020
    links:
      - name: project page & videos
        href: https://orybkin.github.io/video-gcp/
      - name: arXiv
        href: https://arxiv.org/abs/2006.13205
      - name: video (1 min)
        href: https://www.youtube.com/watch?v=axXx-x86IeY&feature=emb_logo
      - name: talk (5 min)
        href: https://youtu.be/w32twGTWvDU
      - name: code
        href: https://github.com/orybkin/video-gcp
      - name: review (Andrew Melnik)
        href: https://www.youtube.com/watch?v=bbIQepxyaVw
    description: Using hierarchical goal-conditioned predictive models, we scale to very long horizon prediction of more than 500 frames. The model is also useful for hierarchical visual planning and long-horizon control.
    highlighted: true

  - name: SSA
    title:
      link: https://arxiv.org/pdf/1912.12773.pdf
      name: Learning Predictive Models From Observation and Interaction
    authors:
      - name: Karl Schmeckpeper
        hre: https://sites.google.com/view/karlschmeckpeper
      - name: Annie Xie
        href: https://anxie.github.io
      - me: true
      - name: Stephen Tian
        href: https://s-tian.github.io
      - name: Kostas Daniilidis
        href: http://www.cis.upenn.edu/~kostas
      - name: Sergey Levine
        href: https://people.eecs.berkeley.edu/~svlevine
      - name: Chelsea Finn
        href: https://ai.stanford.edu/~cbfinn/
    conference:
      name: European Conference on Computer Vision (ECCV)
      year: 2020
    links:
      - name: project page & videos
        href: https://sites.google.com/view/lpmfoai
      - name: arXiv
        href: https://arxiv.org/abs/1912.12773
      - name: video (1 minute)
        href: https://www.youtube.com/watch?v=jWbwh4uZFgU
      - name: talk (5 min)
        href: https://www.youtube.com/watch?v=V_yLQtnS5YE
      - name: workshop version
        href: https://drive.google.com/file/d/1gE8hXP6NEFpoUtpAPH60NkjrzEjCc-Sj/view
    description:  We learn action representations that generalize between robot data and passive observations of other agents (e.g. humans). This enables the use of additional diverse sources of data to train models for visual robotic control.
    highlighted: true

  - name: P2E
    title:
      link: https://arxiv.org/pdf/2005.05960.pdf
      name: Planning to Explore via Self-Supervised World Models
    authors:
      - name: Ramanan Sekar
        href: https://ramanans1.github.io/
        star: true
      - me: true
        star: true
      - name: Kostas Daniilidis
        href: http://www.cis.upenn.edu/~kostas
      - name: Pieter Abbeel
        href: https://people.eecs.berkeley.edu/~pabbeel/
      - name: Danijar Hafner
        href: https://danijar.com/
      - name: Deepak Pathak
        href: https://www.cs.cmu.edu/~dpathak/
    conference:
      name: International Conference on Machine Learning (ICML)
      year: 2020
    links:
      - name: project page & videos
        href: https://ramanans1.github.io/plan2explore/
      - name: arXiv
        href: https://arxiv.org/abs/2005.05960
      - name: video (2 min)
        href: https://www.youtube.com/watch?v=GftqnPWsCWw&feature=emb_logo
      - name: talk (10 min)
        href: https://www.youtube.com/watch?v=gan79mAVfq8
      - name: VentureBeat
        href: https://venturebeat.com/2020/05/13/plan2explore-adapts-to-exploration-tasks-without-fine-tuning/
      - name: blog
        href: https://blog.ml.cmu.edu/2020/10/06/plan2explore/
      - name: code
        href: https://github.com/ramanans1/plan2explore
    description: By planning to explore, as opposed to exploring retrospectively, we significantly improve unsupervised agents. Our agent is able to adapt in a zero/few-shot setup from images, achieving comparable performance to the many-shot oracle.
    highlighted: true

  - name: KeyIn
    title:
      link: https://arxiv.org/pdf/1904.05869.pdf
      name: "Keyframing the Future: Keyframe Discovery for Visual Prediction and Planning"
    authors:
      - name: Karl Pertsch
        href: https://kpertsch.github.io/
        star: true
      - me: true
        star: true
      - name: Jingyun Yang
        href: https://www.linkedin.com/in/yjy0625
      - name: Shenghao Zhou
        href: https://github.com/AZdet
      - name: Kosta Derpanis
        href: http://www.scs.ryerson.ca/kosta/
      - name: Kostas Daniilidis
        href: http://www.cis.upenn.edu/~kostas
      - name: Joseph Lim
        href: http://www-bcf.usc.edu/~limjj/
      - name: Andrew Jaegle
        href: http://www.drewjaegle.com/
    conference:
      name: Conference on Learning for Dynamics and Control (L4DC)
      year: 2020
    links:
      - name: project page & videos
        href: https://sites.google.com/view/keyin
      - name: arXiv
        href: https://arxiv.org/abs/1904.05869
      - name: poster
        href: images/KeyIn_poster.pdf
      - name: slides
        href: https://docs.google.com/presentation/d/154jEGsWOStl46DvZvam3HVTGyi8KslLy8lP6ClkiEE8/edit?usp=sharing
      - name: talk (5 min)
        href: https://www.youtube.com/watch?v=e2hVV5FDKf8&feature=emb_logo
    description: We discover keyframes in videos by learning to select frames that enable prediction of the entire sequence. By using the keyframe structure of the data for prediction, our method is further able to perform planning for longer horizons.

  - name: CLASP
    title:
      link: https://openreview.net/pdf?id=SylPMnR9Ym
      name: Learning what you can do before doing anything
    authors:
      - me: true
        star: true
      - name: Karl Pertsch
        href: https://kpertsch.github.io/
        star: true
      - name: Kosta Derpanis
        href: http://www.scs.ryerson.ca/kosta/
      - name: Kostas Daniilidis
        href: http://www.cis.upenn.edu/~kostas
      - name: Andrew Jaegle
        href: http://www.drewjaegle.com/
    conference:
      name: International Conference on Learning Representations (ICLR)
      year: 2019
    links:
      - name: project page & videos
        href: https://daniilidis-group.github.io/learned_action_spaces/
      - name: paper
        href: https://openreview.net/pdf?id=SylPMnR9Ym
      - name: poster
        href: images/CLASP_poster.pdf
      - name: slides
        href: https://docs.google.com/presentation/d/1sGfvcLdEl_BAlPqtoTPchxKNnBDiiCWuzRSz4lWH07E/edit?usp=sharing
    description: We learn to discover an agent's action space along with a dynamics model from pure video data. The model can be used for model predictive control, requiring orders of magnitude fewer action-annotated videos than other methods.
    nogif: true

  - name: pixel_metrics
    title:
      link: https://medium.com/@olegrybkin_20684/the-reasonable-ineffectiveness-of-mse-pixel-loss-for-future-prediction-and-what-to-do-about-it-4dca8152355d
      name: The reasonable ineffectiveness of pixel metrics for future prediction
    authors:
      - me: true
    conference:
      name: Blog post
      year: 2018
    links:
    description: MSE loss and its variants are commonly used for training and evaluation of future prediction. But is this the right thing to do?
